{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "class SpatialTransformer(nn.Module):\n",
    "    # 2D or 3d spatial transformer network to calculate the warped moving image\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.grid_dict = {}\n",
    "        self.norm_coeff_dict = {}\n",
    "\n",
    "    def forward(self, input_image, flow):\n",
    "        '''\n",
    "        input_image: (n, 1, h, w) or (n, 1, d, h, w)\n",
    "        flow: (n, 2, h, w) or (n, 3, d, h, w)\n",
    "\n",
    "        return:\n",
    "            warped moving image, (n, 1, h, w) or (n, 1, d, h, w)\n",
    "        '''\n",
    "        img_shape = input_image.shape[2:]\n",
    "        if img_shape in self.grid_dict:\n",
    "            grid = self.grid_dict[img_shape]\n",
    "            norm_coeff = self.norm_coeff_dict[img_shape]\n",
    "        else:\n",
    "            grids = torch.meshgrid([torch.arange(0, s) for s in img_shape])\n",
    "            grid = torch.stack(grids[::-1],\n",
    "                               dim=0)  # 2 x h x w or 3 x d x h x w, the data in second dimension is in the order of [w, h, d]\n",
    "            grid = torch.unsqueeze(grid, 0)\n",
    "            grid = grid.to(dtype=flow.dtype, device=flow.device)\n",
    "            norm_coeff = 2. / (torch.tensor(img_shape[::-1], dtype=flow.dtype,\n",
    "                                            device=flow.device) - 1.)  # the coefficients to map image coordinates to [-1, 1]\n",
    "            self.grid_dict[img_shape] = grid\n",
    "            self.norm_coeff_dict[img_shape] = norm_coeff\n",
    "            # logging.info(f'\\nAdd grid shape {tuple(img_shape)}')\n",
    "        new_grid = grid + flow\n",
    "\n",
    "        if self.dim == 2:\n",
    "            new_grid = new_grid.permute(0, 2, 3, 1)  # n x h x w x 2\n",
    "        elif self.dim == 3:\n",
    "            new_grid = new_grid.permute(0, 2, 3, 4, 1)  # n x d x h x w x 3\n",
    "\n",
    "        if len(input_image) != len(new_grid):\n",
    "            # make the image shape compatable by broadcasting\n",
    "            input_image += torch.zeros_like(new_grid)\n",
    "            new_grid += torch.zeros_like(input_image)\n",
    "\n",
    "        warped_input_img = F.grid_sample(input_image, new_grid * norm_coeff - 1., mode='bilinear', align_corners=True,\n",
    "                                         padding_mode='border')\n",
    "        return warped_input_img\n",
    "\n",
    "def pixel_to_itk(pixel, origin, spacing):\n",
    "    x = (pixel[0]-1)*spacing[0]+origin[0]\n",
    "    y = (pixel[1]-1)*spacing[1]+origin[1]\n",
    "    z = (pixel[2]-1)*spacing[2]+origin[2]\n",
    "    return [x,y,z]\n",
    "\n",
    "def itk_to_pixel(itk, origin, spacing):\n",
    "    x = (itk[0] -origin[0])/spacing[0]+1\n",
    "    y = (itk[1] -origin[1])/spacing[1]+1\n",
    "    z = (itk[2] -origin[2])/spacing[2]+1\n",
    "    return [x,y,z]\n",
    "\n",
    "def pixel_to_crop_pixel(pixel, crop_range):\n",
    "    x = pixel[0]-crop_range[2]\n",
    "    y = pixel[1]-crop_range[1]\n",
    "    z = pixel[2]-crop_range[0]\n",
    "    return [x,y,z]\n",
    "\n",
    "def inverse_disp(disp, threshold=0.01, max_iteration=20):\n",
    "    '''\n",
    "    compute the inverse field. implementation of \"A simple fixed‐point approach to invert a deformation field\"\n",
    "\n",
    "    disp : (n, 2, h, w) or (n, 3, d, h, w) or (2, h, w) or (3, d, h, w)\n",
    "        displacement field\n",
    "    '''\n",
    "    dim=3\n",
    "    spatial_transformer=SpatialTransformer(dim)\n",
    "    forward_disp = disp.detach().cuda()\n",
    "    if disp.ndim < dim+2:\n",
    "        forward_disp = torch.unsqueeze(forward_disp, 0)\n",
    "    backward_disp = torch.zeros_like(forward_disp)\n",
    "    backward_disp_old = backward_disp.clone()\n",
    "    for i in range(max_iteration):\n",
    "        backward_disp = -spatial_transformer(forward_disp, backward_disp)\n",
    "        diff = torch.max(torch.abs(backward_disp - backward_disp_old)).item()\n",
    "        if diff < threshold:\n",
    "            break\n",
    "        backward_disp_old = backward_disp.clone()\n",
    "    if disp.ndim < dim + 2:\n",
    "        backward_disp = torch.squeeze(backward_disp, 0)\n",
    "\n",
    "    return backward_disp\n",
    "\n",
    "def get_dvf(coordinate_itk, origin, spacing,crop_range, disp_m2f):\n",
    "    coordinate_pixel = itk_to_pixel(coordinate_itk,origin, spacing)\n",
    "    coordinate_crop_pixel = pixel_to_crop_pixel(coordinate_pixel, crop_range)\n",
    "\n",
    "    image_shape = disp_m2f.size()[1:]\n",
    "    grid_tuple = [np.arange(grid_length, dtype=np.float32) for grid_length in image_shape]\n",
    "\n",
    "    inter = interpolate.RegularGridInterpolator(grid_tuple,\n",
    "                                                np.moveaxis(disp_m2f.detach().cpu().numpy(), 0, -1))\n",
    "    pred = inter(np.flip(coordinate_crop_pixel,0))\n",
    "    x = pred[0][0]*spacing[0]\n",
    "    y = pred[0][1]*spacing[1]\n",
    "    z = pred[0][2]*spacing[2]\n",
    "    return [round(coordinate_itk[0]+x,2),\n",
    "            round(coordinate_itk[1]+y,2),\n",
    "            round(coordinate_itk[2]+z,2)]\n",
    "\n",
    "def get_start_end_needle(str_ori):\n",
    "    \"\"\"\n",
    "    input: [120.835 -60.0364 17.1076]  [55.7537 129.078 17.1076]\n",
    "    func: 将上述string转成start和end两个数组\n",
    "    output: start和end两个数组\n",
    "    \"\"\"\n",
    "    index1 = str_ori.index(\"[\")\n",
    "    index2 = str_ori.index(\"]  [\")\n",
    "    str_start = str_ori[index1 + 1:index2]\n",
    "    str_end = str_ori[index2 + 4:-1]\n",
    "    x_start = float(str_start.split(' ')[0])\n",
    "    y_start = float(str_start.split(' ')[1])\n",
    "    z_start = float(str_start.split(' ')[2])\n",
    "\n",
    "    x_end = float(str_end.split(' ')[0])\n",
    "    y_end = float(str_end.split(' ')[1])\n",
    "    z_end = float(str_end.split(' ')[2])\n",
    "    return [x_start,y_start,z_start],[x_end,y_end,z_end]\n",
    "\n",
    "def get_seed(str_ori):\n",
    "    \"\"\"\n",
    "    input: [63.8889 105.439 17.1076]\n",
    "    func: 将上述string转成数组\n",
    "    output: 数组[x,y,z]\n",
    "    \"\"\"\n",
    "    str_ori = str_ori[1:-1]\n",
    "    x = float(str_ori.split(' ')[0])\n",
    "    y = float(str_ori.split(' ')[1])\n",
    "    z = float(str_ori.split(' ')[2])\n",
    "    return [x,y,z]\n",
    "\n",
    "def get_start_end_seed_list():\n",
    "    start_list=[]\n",
    "    end_list=[]\n",
    "    seed_list=[]\n",
    "    with open(\"plan.needle\", \"r\") as fo:  # 打开文件\n",
    "        for line in fo.readlines():                          #依次读取每行\n",
    "            line = line.strip()                             #去掉每行头尾空白\n",
    "            start, end = get_start_end_needle(line)\n",
    "            start_list.append(start)\n",
    "            end_list.append(end)\n",
    "        # 关闭文件\n",
    "        fo.close()\n",
    "\n",
    "    with open(\"plan.seed\", \"r\") as fo:  # 打开文件\n",
    "        for line in fo.readlines():                          #依次读取每行\n",
    "            line = line.strip()                             #去掉每行头尾空白\n",
    "            seed = get_seed(line)\n",
    "            seed_list.append(seed)\n",
    "        # 关闭文件\n",
    "        fo.close()\n",
    "    return start_list,end_list,seed_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "origin_itk = [-250,-201,-158.5]\n",
    "pixel_spacing = [0.9766, 0.9766, 5]\n",
    "crop_range = [0,170,50]\n",
    "disp_f2m = torch.load('./disp.pth')[5]\n",
    "disp_m2f = inverse_disp(disp_f2m, threshold=0.01, max_iteration=20)\n",
    "start_list, end_list, seed_list = get_start_end_seed_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原坐标： [55.7537, 129.078, 17.1076]\n",
      "新坐标： [55.4, 126.08, 23.03]\n",
      "原坐标： [32.0171, 121.311, 7.75172]\n",
      "新坐标： [32.11, 119.17, 14.61]\n",
      "原坐标： [41.3269, 124.507, 22.3141]\n",
      "新坐标： [41.57, 121.58, 28.42]\n",
      "原坐标： [60.4165, 125.073, 21.1303]\n",
      "新坐标： [60.1, 121.88, 27.49]\n",
      "原坐标： [37.187, 123.36, -2.52513]\n",
      "新坐标： [37.14, 121.26, 5.46]\n",
      "原坐标： [45.9483, 110.915, 36.7143]\n",
      "新坐标： [46.15, 109.35, 42.39]\n",
      "原坐标： [77.3006, 122.53, 3.4654]\n",
      "新坐标： [76.86, 119.27, 9.79]\n",
      "原坐标： [30.8012, 119.034, 0.626806]\n",
      "新坐标： [30.83, 116.92, 8.47]\n",
      "原坐标： [52.3672, 118.42, 36.0254]\n",
      "新坐标： [52.4, 115.88, 41.82]\n",
      "原坐标： [30.4098, 111.339, 37.4032]\n",
      "新坐标： [30.78, 109.91, 41.76]\n",
      "原坐标： [65.3505, 125.655, 26.8033]\n",
      "新坐标： [65.11, 121.95, 33.74]\n",
      "原坐标： [41.225, 124.673, -14.6858]\n",
      "新坐标： [41.17, 123.15, -6.64]\n",
      "原坐标： [48.773, 129.703, -22.9932]\n",
      "新坐标： [48.94, 128.11, -14.35]\n",
      "原坐标： [29.244, 117.653, 16.4379]\n",
      "新坐标： [29.24, 115.57, 21.71]\n",
      "原坐标： [44.5351, 106.11, 54.5189]\n",
      "新坐标： [44.74, 105.07, 59.51]\n",
      "原坐标： [77.21, 117.818, -11.1537]\n",
      "新坐标： [76.68, 113.93, -3.8]\n"
     ]
    }
   ],
   "source": [
    "for end in end_list:\n",
    "    print('原坐标：',end)\n",
    "    dvf = get_dvf(coordinate_itk=end, origin=origin_itk,\n",
    "            spacing=pixel_spacing,crop_range = crop_range,\n",
    "            disp_m2f=disp_m2f)\n",
    "    print('新坐标：',dvf)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}